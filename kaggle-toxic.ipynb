{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col='id')\n",
    "df_test = pd.read_csv('test.csv', index_col='id')\n",
    "\n",
    "df_train['comment_text'].fillna('', inplace=True)\n",
    "\n",
    "df_test['comment_text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_tokens = df_train.comment_text.apply(gensim.utils.simple_preprocess)\n",
    "phrases = gensim.models.phrases.Phrases(simple_tokens)\n",
    "tokenizer = gensim.models.phrases.Phraser(phrases)\n",
    "tokenized_text = list(tokenizer[simple_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_dict = gensim.corpora.dictionary.Dictionary(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_c = df_train.columns[1:]\n",
    "targets = df_train[target_c].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec on comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQ = 100\n",
    "word2vec = gensim.models.word2vec.Word2Vec(tokenized_text, window=5, size=MAX_SEQ, min_count=3, workers=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.wv.most_similar('hell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index shift due to padding, starts from 0\n",
    "docs = [[idx + 1 for idx in corpus_dict.doc2idx(doc)]  for doc in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "padded_docs = keras.preprocessing.sequence.pad_sequences(docs, maxlen=MAX_SEQ, truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_index = max(c for d in docs for c in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = np.array([np.random.normal(size=word2vec.vector_size)]+ # for the '0' padding word\n",
    "                      [word2vec.wv[corpus_dict[idx]]\n",
    "                      if corpus_dict[idx] in word2vec.wv.vocab\n",
    "                      else np.random.normal(size=word2vec.vector_size)\n",
    "                      for idx in range(max_index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_embedding(tokens):\n",
    "    embeddings = [word2vec.wv[t] / word2vec.wv.vocab[t].count for t in tokens if t in word2vec.wv.vocab]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec.vector_size)\n",
    "\n",
    "def text_to_embedding(text):\n",
    "    return tokens_to_embedding(tokenizer[gensim.utils.simple_preprocess(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used this to save sessions of the notebook\n",
    "# import dill\n",
    "# #dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile,EMB_DIM, my_dict,em2):\n",
    "    print('Reading {}'.format(gloveFile))\n",
    "    print (\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        model[word] = embedding\n",
    "        \n",
    "    embedding_matrix = np.zeros((len(my_dict) + 1, EMB_DIM))\n",
    "    \n",
    "    for word,i in my_dict.items():\n",
    "        embedding_vector = model.get(i)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word] = embedding_vector  \n",
    "        else:\n",
    "            if i in word2vec.wv.vocab:\n",
    "                embedding_matrix[word] = word2vec.wv[i][np.newaxis,:]\n",
    "    print('Done')\n",
    "        \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previously saved session\n",
    "# import dill\n",
    "# dill.load_session('D:\\kaggleStuff\\toxic-comment\\notebook_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = loadGloveModel('D:\\kaggleStuff\\embeddings\\glove.twitter.27B.'+ str(MAX_SEQ) +'d.txt', MAX_SEQ, corpus_dict,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_matrix[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Input, LSTM, GRU,Embedding, Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_index + 1, MAX_SEQ, weights=[embedding_matrix], \n",
    "                  input_length=MAX_SEQ))\n",
    "model.add(Bidirectional(GRU(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(6, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 2\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(df_train) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.001, 0.0001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.001, decay=lr_decay)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])\n",
    "\n",
    "model.fit(padded_docs, targets, batch_size=batch_size,epochs=epochs,\n",
    "          validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This might take some time, would be better to do it at the start and save the session\n",
    "test_inputs =  np.array([text_to_embedding(doc) for doc in df_test.comment_text])\n",
    "\n",
    "test_outputs = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df = df_test.reset_index()[['id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, target_class in enumerate(target_c):\n",
    "    output_df[target_class] = test_outputs[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv('sol_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
